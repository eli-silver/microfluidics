"""
This script will correct for vignetting and saturation loss at the edges of a picamera v2 image.

It uses unmixing matrices generated by ``picam_raw_analysis.unmixing_matrix``.

It can be run from the command line:

.. code-block:: bash

    python -m picam_raw_analysis.unmix_image path/to/calibration/folder image.jpg

Use the ``--help`` flag to obtain a usage message.

Copyright Richard Bowman 2019, released under GNU GPL v3 or later

"""
from __future__ import print_function, division

import numpy as np
import scipy.interpolate
import scipy.ndimage
from . import unmixing_matrix
from .extract_raw_image import load_raw_image
import argparse
import cv2
import os.path

# The code below was an aborted attempt to improve performance
# def brokenupsample_1d(arr, axis=0, zoom=16):
#     """Upscale one dimension of an array"""
#     naxes = len(arr.shape)
#     def pad(sl, filler=slice(None)):
#         """A convenience function to embed a given object/slice in n dimensions"""
#         s = (filler, ) * naxes
#         s[axis] = sl
#         return s
#     repeated = np.repeat(arr, zoom, axis=axis)
#     # p and q are the arrays we interpolate between.
#     # p puts the blocks corresponding to the input array's elements to the left
#     # q puts them to the right.  We overwrite the wrapped-around bits to do linear
#     # interpolation.
#     # if zoom is even, then no pixel will correspond exactly to an input pixel, as
#     # we centre the window on the input array elements.
#     assert zoom % 2 == 0, "This function currently only is tested for even zoom values"
#     start = 0.5# - (zoom % 2)/2.  # if zoom is odd, the centre of each block is exact
#                                  # otherwise, the "exact points" are between blocks
#     p = np.roll(repeated, -zoom//2, axis=axis)
#     p[pad(slice(-zoom//2, None))] = arr[pad(slice(-2))][pad(np.newaxis)]
#     q = np.roll(repeated, zoom//2, axis=axis)
#     q[pad(slice(None,zoom//2))] = arr[pad(slice(1))][pad(np.newaxis)]
#     x = np.arange(0, arr.shape[axis], 1/zoom) - (zoom - 1)/(zoom*2. )
#     a = np.concatenate((
#         np.arange(zoom//2 - 1 + start, 0, -1)/zoom + 1, # should have rshift elements, all >1
        
#     ))

def upsample_1d(arr, axis=0, zoom=16):
    """Upsample one dimension of an array"""
    x = np.arange(arr.shape[axis])
    f = scipy.interpolate.interp1d(x, arr, axis=axis, kind="linear", fill_value="extrapolate")
    new_x = np.arange(0, arr.shape[axis], 1/zoom) - (zoom - 1)/(zoom*2. )
    return f(new_x)


def upsample_xy(arr, zoom=16):
    """Upscale the X and Y dimensions of an image/spatially varying matrix"""
    print("Array with size {} being zoomed by a factor of {}".format(arr.shape, zoom))
    # Initially this used scipy.ndimage.zoom, but that caused memory problems
    #zoom_values = np.ones(len(arr.shape))
    #zoom_values[0:2] = zoom
    #return scipy.ndimage.zoom(arr, zoom, mode="nearest", order=1)
    return upsample_1d(upsample_1d(arr, axis=0, zoom=zoom), axis=1, zoom=zoom)


def correct_image(image, unmixing_matrix=None, norm_to_white=None):
    """Process an image to remove vignetting and saturation loss.

    The image should be an NxMx3 numpy array.

    The unmixing matrix should be an NxMx3x3 array.

    The normalisation image should be NxMx3
    """
    if norm_to_white is None:
        norm_to_white = np.ones_like(image)
    if unmixing_matrix is None:
        return image * norm_to_white
    else:
        #check this function for possible r-g swap?
        return np.sum(unmixing_matrix * image[:,:,np.newaxis,:] * norm_to_white[:,:,np.newaxis,:], axis=-1)

def main():
    """Process images from the command line"""
    parser = argparse.ArgumentParser(description="Post-process Raspberry Pi camera module v2 images to remove vignetting and colour crosstalk.")
    unmixing_matrix.add_unmixing_args(parser)
    parser.add_argument("--white_image", help="Override the white image to use a different vignetting correction")
    parser.add_argument("--normalise", action="store_true", help="Normalise the overall brightness of the image")
    parser.add_argument("--extend_range", type=float, default=1, help="Divide the image by this number (set it to >1 for some extra headroom).  Pointless if used with --normlise.")
    parser.add_argument("--allow_overflow", action="store_true", help="Use this option to suppress clipping of the image, if the corrected image is too bright to show.")
    parser.add_argument("--disable_unmixing", action="store_true", help="Disable the unmixing matrix (i.e. only correct for vignetting)")
    parser.add_argument("--disable_vignetting", action="store_true", help="Disable the vignetting correction (probably a bad idea)")
    parser.add_argument("--sixteen_bit", action="store_true", help="Save the output image as a 16-bit TIFF (default is 8-bit)")
    parser.add_argument("--smooth_image", type=float, default=0, help="Smooth the images before processing (width of Gaussian in pixels, default is 0, no smoothing)")
    parser.add_argument("image", nargs="+", help="Filenames of images to process, or a file called 'file_names.txt' with all image names listed line by line.")
    args = parser.parse_args()

    imageNames = [] #file names of images
    if args.image[0] == "file_names.txt":  #if a batch file name file was provided, load in the individual names 
        #read in file_names.txt and add each name to this list!
        f = open(args.calibration + "file_names.txt", 'r') 
        print('Images that will be processed:')
        for line in f:
            print(line.rstrip('\n'))
            imageNames.append(line.rstrip('\n'))
        f.close()

    else:       #if individual image file name(s() were provided on the command line, store the provided names
        imageNames = args.image

    image = load_raw_image(imageNames[0]).demosaic()
    print("First image has shape {}".format(image.shape))

    # Load the calibration (this will be either from a YAML file, or calculated from images)
    cal = unmixing_matrix.calculate_calibration(args)
    unmixing_matrices = cal['unmixing_matrices']
    white_image = cal['white_image']
    assert white_image.shape == unmixing_matrices.shape[:3], "White image and unmixing matrices have different sizes!"
    assert unmixing_matrices.shape[2:4] == (3, 3), "Unmixing matrix must be NxMx3x3!"

    # Check the sizes are compatible, and upsample the matrix if needed
    ds = unmixing_matrix.DOWNSAMPLING
    crop = (slice(None),) * 3
    if unmixing_matrices.shape[:3] == image.shape:
        pass # Everything's the right shape - do nothing
    elif unmixing_matrices.shape[0] == image.shape[0]//ds:
        assert unmixing_matrices.shape[1] == image.shape[1]//ds, "Downsampling looks different in X and Y!"
        # Crop the image if it's slightly too big (probably a downsampling artefact)
        if unmixing_matrices.shape[0]*ds < image.shape[0] or unmixing_matrices.shape[1]*ds < image.shape[1]:
            print("Warning: some pixels were trimmed from the calibration; output images will be smaller than input.")
            crop = (slice(0, unmixing_matrices.shape[0]*ds),
                    slice(0, unmixing_matrices.shape[1]*ds),
                    3, )
        unmixing_matrices = upsample_xy(unmixing_matrices, ds)
    else:
        raise ValueError("The unmixing matrices were neither the right size, nor correctly downsampled.")
    

    # Override the normalisation image if specified
    if args.white_image is not None:
        white_image = unmixing_matrix.load_raw_image_and_bin(args.white_image)

    # Make sure the white image matches the size of the unmixing matrices
    if white_image.shape[0]//ds == unmixing_matrices.shape[0]//ds:
        assert white_image.shape[1]//ds == unmixing_matrices.shape[1]//ds, "Downsampling of white image looks different in X and Y!"
        white_image = white_image[crop] # Everything's the right shape (to within 16 pixels)
    elif white_image.shape[0] == unmixing_matrices.shape[0]//ds:
        assert white_image.shape[1] == unmixing_matrices.shape[1]//ds, "Downsampling of white image looks different in X and Y!"
        white_image = upsample_xy(white_image, ds)
    print("White image min: {} max: {}".format(white_image.min(), white_image.max()))
    norm_to_white = 1023. / white_image # Do the normalisation for 10-bit data

    # Disable normalisation or unmixing if required
    if args.disable_unmixing: 
        unmixing_matrices = None
    if args.disable_vignetting:
        norm_to_white = None

    ### Correction happens here! ###
    for fname in imageNames:
        print("Converting: {}".format(fname))
        if fname == imageNames[0]:
            pass
        else:
            image = load_raw_image(fname).demosaic()
        if args.smooth_image > 0:
            image = scipy.ndimage.gaussian_filter(image, (args.smooth_image, args.smooth_image,0), order=0)
        corrected = correct_image(image.astype(float), unmixing_matrix=unmixing_matrices, norm_to_white=norm_to_white)

        # Brightness adjustment
        corrected /= args.extend_range # dim the image to provide more dynamic range
        if args.normalise:             # or just normalise to the brightest value (NB this doesn't affect colour balance)
            corrected *= (2**10-1)/np.max(corrected)
        if not args.allow_overflow:    # clip pixels at max. value
            corrected[corrected > (2**10-1)] = (2**10-1)
            corrected[corrected < 0] = 0

        root_fname, junk = fname.rsplit(".j", 2) #get rid of the .jpeg extension
        print("corrected image shape: " + str(np.shape(corrected)))
        corrected = corrected[:, :, [2,1,0]]     # Swap channels from RGB to BGR for cv2.imwrite compatability
        if args.sixteen_bit:
            print("Writing the 10-bit calibrated image as a 16-bit image to {}_16.tiff".format(root_fname))
            cv2.imwrite(root_fname + "_16.tiff", (corrected*64).astype(np.uint16))
        print("Writing the top 8 bits of the calibrated image to {}.tiff".format(root_fname))
        cv2.imwrite(root_fname + ".tiff", (corrected//4).astype(np.uint8))

    




if __name__ == "__main__":
    main()
